
# Salary Prediction Project

## Vis√£o geral
Projeto para an√°lise e modelagem de previs√£o de sal√°rios (regress√£o e classifica√ß√£o) a partir do dataset `salary_prepared_with_targets.csv`.

O reposit√≥rio inclui:
- EDA (an√°lise explorat√≥ria)
- Modelos: Regress√£o Linear e Regress√£o Log√≠stica
- Pipeline simples de pr√©-processamento
- Scripts organizados em `src/`
- Notebook e relat√≥rios gerados

## Estrutura do projeto
```
salary_project/
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ eda.py
    ‚îú‚îÄ‚îÄ model_regression.py
    ‚îú‚îÄ‚îÄ model_classification.py
    ‚îú‚îÄ‚îÄ preprocessing.py
    ‚îî‚îÄ‚îÄ utils.py
```


## Como usar (local / VS Code)
1. Coloque `salary_prepared_with_targets.csv` na raiz do projeto (mesmo n√≠vel de `main.py`).
2. Instale depend√™ncias:
```bash
pip install -r requirements.txt
```
3. Rodar app:
```bash
python main.py
```

## Instalando como pacote (opcional)
Para instalar localmente como pacote:
```bash
pip install .
```
Isso instalar√° o pacote `salary_project` e voc√™ poder√° importar fun√ß√µes no Python.


# Resumo Executivo: Previs√£o de Sal√°rios - Regress√£o vs. Classifica√ß√£o

## üìã S√≠ntese da Atividade

Este projeto explorou dois paradigmas complementares para an√°lise de dados salariais usando o dataset "Salary Prediction Classification" do Kaggle (32.561 registros). A atividade comparou a abordagem de **regress√£o linear** (prever sal√°rio cont√≠nuo) com a de **regress√£o log√≠stica** (classificar em categorias de sal√°rio), investigando quando cada m√©todo √© mais apropriado.

---

## üìä An√°lise Explorat√≥ria dos Dados (EDA)

### **Caracter√≠sticas do Dataset**
- **Tamanho**: 32.561 observa√ß√µes com 17 vari√°veis
- **Composi√ß√£o**: 8 vari√°veis num√©ricas e 9 categ√≥ricas
- **Valores Faltantes**: Nenhum (ap√≥s limpeza)

### **Vari√°veis Num√©ricas - Estat√≠sticas Descritivas**

| Vari√°vel | M√©dia | Desvio Padr√£o | M√≠nimo | Q1 | Mediana | Q3 | M√°ximo |
|----------|-------|---------------|--------|-----|---------|-----|--------|
| **age** | 38,58 | 13,64 | 17 | 28 | 37 | 48 | 90 |
| **fnlwgt** | 189.778 | 105.550 | 12.285 | 117.827 | 178.356 | 237.051 | 1.484.705 |
| **education-num** | 10,09 | 2,57 | 1 | 9 | 10 | 13 | 16 |
| **capital-gain** | 1.077,65 | 7.385,29 | 0 | 0 | 0 | 0 | 99.999 |
| **capital-loss** | 87,30 | 402,96 | 0 | 0 | 0 | 0 | 4.356 |
| **hours-per-week** | 40,44 | 12,39 | 1 | 40 | 40 | 45 | 99 |

**Insights**: A idade m√©dia de ~39 anos reflete uma for√ßa de trabalho madura. A mediana de horas semanais (40h) √© o padr√£o, mas h√° varia√ß√£o consider√°vel. Capital-gain/loss s√£o zeros em maioria (75% quartil inferior = 0), indicando alta assimetria.

### **Distribui√ß√£o da Vari√°vel Target**

**Classe 0 (Sal√°rio ‚â§ $50K)**: 24.720 casos (75,92%)  
**Classe 1 (Sal√°rio > $50K)**: 7.841 casos (24,08%)

‚ö†Ô∏è **Dataset Desbalanceado**: A propor√ß√£o 75%-25% indica desbalanceamento moderado. Modelos tendem a priorizar a classe majorit√°ria, afetando recall da classe minorit√°ria.

### **Correla√ß√£o com Target** (salary_numeric_proxy)

| Vari√°vel | Correla√ß√£o |
|----------|-----------|
| education-num | +0,335 |
| age | +0,234 |
| hours-per-week | +0,229 |
| capital-gain | +0,223 |
| capital-loss | +0,151 |
| fnlwgt | -0,009 |

**Achados principais**:
- **Educa√ß√£o** √© o preditor mais forte (r=0,34): mais anos de educa√ß√£o correlacionam com sal√°rio mais alto
- **Idade** tem correla√ß√£o positiva (r=0,23): experi√™ncia influencia sal√°rio
- **Horas trabalhadas** (r=0,23): trabalhar mais associa-se a sal√°rios mais altos
- **Ganhos de capital** (r=0,22): investimentos influenciam classe salarial
- **Peso da amostra (fnlwgt)** quase n√£o correlaciona: vari√°vel t√©cnica, n√£o preditora

### **Vari√°veis Categ√≥ricas - Distribui√ß√£o Principal**

| Vari√°vel | Categoria Principal | Frequ√™ncia |
|----------|---------------------|-----------|
| **workclass** | Private | 22.696 (69,7%) |
| **education** | HS-grad | 10.501 (32,2%) |
| **marital-status** | Married-civ-spouse | 14.976 (46,0%) |
| **occupation** | Prof-specialty | 4.140 (12,7%) |
| **race** | White | 27.816 (85,4%) |
| **sex** | Male | 21.790 (66,9%) |
| **native-country** | United-States | 29.170 (89,6%) |

**Observa√ß√µes**:
- Setor **privado** domina (70% dos dados)
- Maioria com educa√ß√£o **ensino m√©dio** (~32%) ou alguns cursos superiores (~22%)
- **Casados** constituem 46% da amostra
- Distribui√ß√£o **desequilibrada por g√™nero** (67% homens vs 33% mulheres) ‚Äî pode introduzir vi√©s
- Amostra **predominantemente norte-americana e caucasiana** (89% EUA, 85% brancos) ‚Äî restringe generaliza√ß√£o

### **Implica√ß√µes para Modelagem**

1. **Vari√°veis Num√©ricas**: Distribui√ß√µes assim√©tricas (ex: capital-gain) justificam padroniza√ß√£o (StandardScaler)
2. **Categorias Raras**: Algumas categorias em 'native-country' e 'occupation' aparecem <1% ‚Äî one-hot encoding com `drop='first'` evita multicolinearidade
3. **Desbalanceamento**: Import√¢ncia em considerar m√©tricas al√©m de acur√°cia (recall, F1, AUC)
4. **Potencial Vi√©s**: Dados n√£o representam mulheres e minorias proporcionalmente ‚Äî resultados com ressalva

---

## üîç Principais Descobertas

### **Dataset e Prepara√ß√£o dos Dados**
- **Divis√£o Treino/Teste**: 70% / 30% (estratificada na classifica√ß√£o para manter propor√ß√µes de classes)
- **Imputa√ß√£o**: Valores faltantes tratados com mediana (num√©ricas) e moda (categ√≥ricas)
- **Codifica√ß√£o**: One-hot encoding das 9 vari√°veis categ√≥ricas com `drop='first'` para evitar multicolinearidade
- **Padroniza√ß√£o**: StandardScaler aplicado √†s 8 vari√°veis num√©ricas para garantir igualdade de escala

---

## üìä Resultados dos Modelos

### **Modelo 1: Regress√£o Linear**
| M√©trica | Valor |
|---------|-------|
| MAE (Erro Absoluto M√©dio) | $10.579,89 |
| RMSE (Raiz do Erro Quadr√°tico M√©dio) | $13.612,42 |
| R¬≤ (Coeficiente de Determina√ß√£o) | 0,3593 |

**Interpreta√ß√£o**: O modelo explica apenas ~36% da vari√¢ncia nos sal√°rios. O erro m√©dio de $10.579 significa que as previs√µes desviam, em m√©dia, dessa quantia do valor real. Isso indica que vari√°veis cont√≠nuas sozinhas n√£o capturam toda a complexidade do problema.

### **Modelo 2: Regress√£o Log√≠stica (Classifica√ß√£o)**
| M√©trica | Valor |
|---------|-------|
| Acur√°cia | 85,45% |
| Precis√£o | 73,86% |
| Recall (Sensibilidade) | 61,27% |
| F1-Score | 66,98% |
| AUC-ROC | 0,9088 |

**Interpreta√ß√£o**: O modelo classifica corretamente 85% dos casos. Com 91% AUC-ROC, demonstra excelente capacidade discriminativa. A precis√£o de 74% significa que quando prediz "sal√°rio alto", acerta 74% das vezes. O recall de 61% indica que identifica apenas 61% dos casos de sal√°rio alto (limita√ß√£o importante).

---

## ‚öñÔ∏è Compara√ß√£o Entre Abordagens

| Crit√©rio | Regress√£o Linear | Regress√£o Log√≠stica |
|----------|------------------|-------------------|
| **Objetivo** | Prever valor cont√≠nuo | Classificar em categorias |
| **Desempenho** | Modesto (R¬≤=0,36) | Forte (Acur√°cia=85%) |
| **Interpretabilidade** | Simples: coeficientes = mudan√ßa em $Y por unidade de $X$ | Simples: odds ratio para cada feature |
| **Uso Pr√°tico** | Salarial estimado individual | Decis√µes bin√°rias (contratar/benef√≠cios) |
| **Sensibilidade** | Afetado por outliers e escala | Robusto a outliers, baseado em probabilidades |
| **M√©tricas Apropriadas** | MAE, RMSE, R¬≤ | Acur√°cia, Precis√£o, Recall, F1, AUC |

### **Por que a Classifica√ß√£o Superou?**

1. **Alinhamento com os Dados**: O dataset foi originalmente criado com uma **classifica√ß√£o bin√°ria** (‚â§50K vs >50K). A regress√£o for√ßou valores cont√≠nuos (30K e 70K), perdendo informa√ß√£o real.

2. **Natureza do Problema**: Decis√µes de RH (benef√≠cios, categorias salariais) s√£o tipicamente bin√°rias. Classifica√ß√£o √© mais alinhada ao caso de uso real.

3. **Limita√ß√µes da Regress√£o Linear**: 
   - R¬≤ baixo indica que relacionamento linear n√£o captura padr√µes
   - Regress√£o n√£o respeita a natureza discreta do problema original
   - Previs√µes podem ficar fora do intervalo esperado (ex: sal√°rio negativo)

---

## üî¨ An√°lise de Coeficientes e Interpreta√ß√£o

### **Regress√£o Linear - Interpretabilidade**
- **Coeficientes Positivos**: Aumentam o sal√°rio predito
  - Educa√ß√£o: +correla√ß√£o forte ‚Üí cada ano adicional aumenta sal√°rio esperado
  - Idade: +correla√ß√£o ‚Üí experi√™ncia adiciona valor
  - Horas de trabalho: +correla√ß√£o ‚Üí mais horas = sal√°rio maior
- **Limita√ß√£o**: Com R¬≤=0,36, coeficientes explicam pouco da varia√ß√£o total
- **Implica√ß√£o Pr√°tica**: Modelo inadequado para prever sal√°rios individuais com confian√ßa

### **Regress√£o Log√≠stica - Interpretabilidade (Odds Ratio)**
- **Coeficientes** representam mudan√ßa na probabilidade de "sal√°rio alto"
- **Exemplo Interpretativo**: Se coeficiente de educa√ß√£o √© +0,15, cada ano adicional de educa√ß√£o **multiplica as odds de sal√°rio alto por e^0,15 ‚âà 1,16 (+16%)**
- **Vantagem**: Probabilidades s√£o diretas e acion√°veis
  - Resultado: "Probabilidade de sal√°rio >50K para esta pessoa: 72%"
  - Aplic√°vel em decis√µes de neg√≥cio (elegibilidade para benef√≠cios, promo√ß√µes)

---

## üí° Abordagem Recomendada

### **Escolha: Regress√£o Log√≠stica**

**Justificativa:**

1. **Desempenho Superior**: 85% de acur√°cia vs. R¬≤=36% da regress√£o (incompar√°veis, mas a classifica√ß√£o √© muito mais efetiva)

2. **Alinhamento Conceitual**: O problema √© naturalmente bin√°rio (faixa de sal√°rio). For√ßar regress√£o √© um mau-uso do m√©todo.

3. **Probabilidades Interpret√°veis**: Fornece $P(\text{sal√°rio alto})$ para cada pessoa ‚Äî informa√ß√£o acion√°vel.

4. **M√©tricas Adequadas**:
   - AUC-ROC de 0,91 = modelo excelente em discriminar classes
   - Precis√£o 74% = confi√°vel para identificar sal√°rios altos
   - Recall 61% = detecta maioria dos altos sal√°rios (room para melhoria)

5. **Contexto Real**: HR e neg√≥cios pensam em categorias, n√£o em valores cont√≠nuos.

---

## üöÄ Melhorias Propostas

Para otimizar ainda mais a **regress√£o log√≠stica**:

1. **Feature Engineering**:
   - Criar intera√ß√µes entre vari√°veis (ex: idade √ó educa√ß√£o)
   - Polin√¥mios para vari√°veis num√©ricas
   - Agrega√ß√µes de categorias categ√≥ricas raramente frequentes

2. **Regulariza√ß√£o**:
   - Introduzir L1 (Lasso) ou L2 (Ridge) para evitar overfitting
   - Valida√ß√£o cruzada k-fold para sele√ß√£o de hiperpar√¢metros

3. **Balanceamento de Classes**:
   - Dataset √© desbalanceado (76% classe 0, 24% classe 1)
   - Usar SMOTE, class_weight ou threshold ajustado

4. **Modelos Alternativos**:
   - Random Forest / Gradient Boosting (melhor captura de n√£o-linearidades)
   - Ensemble de m√∫ltiplos modelos

5. **An√°lise de Erros**:
   - Investigar os 39% de falsos negativos (sal√°rios altos preditos como baixos)
   - Pode haver clusters n√£o capturados

---

## üìå Conclus√£o

A **regress√£o log√≠stica √© a abordagem recomendada** para este dataset. Enquanto regress√£o linear fornece interpretabilidade, ela √© inadequada para um problema fundamentalmente classificat√≥rio. A regress√£o log√≠stica combina interpretabilidade (importante), desempenho robusto (AUC=0,91) e alinhamento com o contexto real (decis√µes categ√≥ricas em RH).

### **Resumo Executivo Final**

**O que foi feito:**
Desenvolvemos dois modelos preditivos para classificar sal√°rios em faixas (‚â§$50K vs >$50K) usando dataset de 32.561 registros com 17 vari√°veis (econ√¥micas, demogr√°ficas e laborais).

**O que descobrimos:**
1. **Regress√£o Linear** (prever valor cont√≠nuo): R¬≤=0,36, RMSE=$13.612 ‚Üí modelo fraco, inadequado
2. **Regress√£o Log√≠stica** (classifica√ß√£o bin√°ria): Acur√°cia=85%, AUC=0,91 ‚Üí modelo forte, confi√°vel
3. **Fatores Preditivos**: Educa√ß√£o (r=0,34), idade (r=0,23), horas trabalhadas (r=0,23) s√£o os melhores indicadores
4. **Dataset Desbalanceado**: 76% sal√°rios baixos, 24% sal√°rios altos ‚Üí explica recall moderado (61%)

**Qual abordagem escolhemos:**
**Regress√£o Log√≠stica**. Raz√µes:
- Alinha-se com natureza bin√°ria do problema (categorizar pessoas em faixas salariais)
- Fornece probabilidades interpret√°veis ("essa pessoa tem 72% de chance de ganhar >$50K")
- Desempenho superior (AUC=0,91 vs R¬≤=0,36)
- Aplic√°vel diretamente em decis√µes RH (benef√≠cios, promo√ß√µes, recrutamento)
- Coeficientes interpret√°veis como odds ratio (mudan√ßa de probabilidade por unidade de feature)

**Limita√ß√µes Atuais & Pr√≥ximos Passos:**
- Recall de 61% deixa 39% dos sal√°rios altos n√£o-identificados ‚Üí usar SMOTE para balancear classes
- Dataset enviesado (67% homens, 85% EUA) ‚Üí testar em dados mais diversos
- Explorar regulariza√ß√£o (L1/L2) e valida√ß√£o cruzada para melhorar generaliza√ß√£o
- Considerar Gradient Boosting ou Random Forest para capturar n√£o-linearidades

**Impacto Estimado**: Modelo final pode economizar tempo em triagem de candidatos, com 91% de confian√ßa na discrimina√ß√£o entre sal√°rios alto/baixo.

---

**Data**: 17 de novembro de 2025  
**Dataset**: Salary Prediction Classification (Kaggle)  
**Ferramentas**: Python, scikit-learn, pandas  
**Divis√£o**: 70% treino / 30% teste (estratificada)  
**Status**: ‚úÖ Conclu√≠do

