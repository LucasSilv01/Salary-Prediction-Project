
# Salary Prediction Project

## Vis√£o geral
Projeto para an√°lise e modelagem de previs√£o de sal√°rios (regress√£o e classifica√ß√£o) a partir do dataset `salary_prepared_with_targets.csv`.

O reposit√≥rio inclui:
- EDA (an√°lise explorat√≥ria)
- Modelos: Regress√£o Linear e Regress√£o Log√≠stica
- Pipeline simples de pr√©-processamento
- Scripts organizados em `src/`
- Notebook e relat√≥rios gerados

## Estrutura do projeto
```
salary_project/
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ eda.py
    ‚îú‚îÄ‚îÄ model_regression.py
    ‚îú‚îÄ‚îÄ model_classification.py
    ‚îú‚îÄ‚îÄ preprocessing.py
    ‚îî‚îÄ‚îÄ utils.py
```


## Como usar (local / VS Code)
1. Coloque `salary_prepared_with_targets.csv` na raiz do projeto (mesmo n√≠vel de `main.py`).
2. Instale depend√™ncias:
```bash
pip install -r requirements.txt
```
3. Rodar app:
```bash
python main.py
```

## Instalando como pacote (opcional)
Para instalar localmente como pacote:
```bash
pip install .
```
Isso instalar√° o pacote `salary_project` e voc√™ poder√° importar fun√ß√µes no Python.


# Resumo Executivo: Previs√£o de Sal√°rios - Regress√£o vs. Classifica√ß√£o

## üìã S√≠ntese da Atividade

Este projeto explorou dois paradigmas complementares para an√°lise de dados salariais usando o dataset "Salary Prediction Classification" do Kaggle (32.561 registros). A atividade comparou a abordagem de **regress√£o linear** (prever sal√°rio cont√≠nuo) com a de **regress√£o log√≠stica** (classificar em categorias de sal√°rio), investigando quando cada m√©todo √© mais apropriado.

---

## üîç Principais Descobertas

### **Dataset e Prepara√ß√£o**
- **Tamanho**: 32.561 observa√ß√µes com 17 vari√°veis (6 num√©ricas, 8 categ√≥ricas)
- **Vari√°vel Alvo Original**: `salary` (bin√°ria: ‚â§50K vs >50K)
- **Engenharia de Features**: 
  - Cria√ß√£o de `salary_numeric_proxy` para regress√£o (valores cont√≠nuos: 30.000 e 70.000)
  - Manuten√ß√£o de `salary_class` (0/1) para classifica√ß√£o
  - Imputa√ß√£o de valores faltantes (mediana para num√©ricos, moda para categ√≥ricos)
  - Codifica√ß√£o one-hot das 8 vari√°veis categ√≥ricas
  - Padroniza√ß√£o das vari√°veis num√©ricas (StandardScaler)
- **Divis√£o Treino/Teste**: 70% / 30% (estratificada na classifica√ß√£o)

---

## üìä Resultados dos Modelos

### **Modelo 1: Regress√£o Linear**
| M√©trica | Valor |
|---------|-------|
| MAE (Erro Absoluto M√©dio) | $10.579,89 |
| RMSE (Raiz do Erro Quadr√°tico M√©dio) | $13.612,42 |
| R¬≤ (Coeficiente de Determina√ß√£o) | 0,3593 |

**Interpreta√ß√£o**: O modelo explica apenas ~36% da vari√¢ncia nos sal√°rios. O erro m√©dio de $10.579 significa que as previs√µes desviam, em m√©dia, dessa quantia do valor real. Isso indica que vari√°veis cont√≠nuas sozinhas n√£o capturam toda a complexidade do problema.

### **Modelo 2: Regress√£o Log√≠stica (Classifica√ß√£o)**
| M√©trica | Valor |
|---------|-------|
| Acur√°cia | 85,45% |
| Precis√£o | 73,86% |
| Recall (Sensibilidade) | 61,27% |
| F1-Score | 66,98% |
| AUC-ROC | 0,9088 |

**Interpreta√ß√£o**: O modelo classifica corretamente 85% dos casos. Com 91% AUC-ROC, demonstra excelente capacidade discriminativa. A precis√£o de 74% significa que quando prediz "sal√°rio alto", acerta 74% das vezes. O recall de 61% indica que identifica apenas 61% dos casos de sal√°rio alto (limita√ß√£o importante).

---

## ‚öñÔ∏è Compara√ß√£o Entre Abordagens

| Crit√©rio | Regress√£o Linear | Regress√£o Log√≠stica |
|----------|------------------|-------------------|
| **Objetivo** | Prever valor cont√≠nuo | Classificar em categorias |
| **Desempenho** | Modesto (R¬≤=0,36) | Forte (Acur√°cia=85%) |
| **Interpretabilidade** | Simples: coeficientes = mudan√ßa em $Y por unidade de $X$ | Simples: odds ratio para cada feature |
| **Uso Pr√°tico** | Salarial estimado individual | Decis√µes bin√°rias (contratar/benef√≠cios) |
| **Sensibilidade** | Afetado por outliers e escala | Robusto a outliers, baseado em probabilidades |
| **M√©tricas Apropriadas** | MAE, RMSE, R¬≤ | Acur√°cia, Precis√£o, Recall, F1, AUC |

### **Por que a Classifica√ß√£o Superou?**

1. **Alinhamento com os Dados**: O dataset foi originalmente criado com uma **classifica√ß√£o bin√°ria** (‚â§50K vs >50K). A regress√£o for√ßou valores cont√≠nuos (30K e 70K), perdendo informa√ß√£o real.

2. **Natureza do Problema**: Decis√µes de RH (benef√≠cios, categorias salariais) s√£o tipicamente bin√°rias. Classifica√ß√£o √© mais alinhada ao caso de uso real.

3. **Limita√ß√µes da Regress√£o Linear**: 
   - R¬≤ baixo indica que relacionamento linear n√£o captura padr√µes
   - Regress√£o n√£o respeita a natureza discreta do problema original
   - Previs√µes podem ficar fora do intervalo esperado (ex: sal√°rio negativo)

---

## üí° Abordagem Recomendada

### **Escolha: Regress√£o Log√≠stica**

**Justificativa:**

1. **Desempenho Superior**: 85% de acur√°cia vs. R¬≤=36% da regress√£o (incompar√°veis, mas a classifica√ß√£o √© muito mais efetiva)

2. **Alinhamento Conceitual**: O problema √© naturalmente bin√°rio (faixa de sal√°rio). For√ßar regress√£o √© um mau-uso do m√©todo.

3. **Probabilidades Interpret√°veis**: Fornece $P(\text{sal√°rio alto})$ para cada pessoa ‚Äî informa√ß√£o acion√°vel.

4. **M√©tricas Adequadas**:
   - AUC-ROC de 0,91 = modelo excelente em discriminar classes
   - Precis√£o 74% = confi√°vel para identificar sal√°rios altos
   - Recall 61% = detecta maioria dos altos sal√°rios (room para melhoria)

5. **Contexto Real**: HR e neg√≥cios pensam em categorias, n√£o em valores cont√≠nuos.

---

## üöÄ Melhorias Propostas

Para otimizar ainda mais a **regress√£o log√≠stica**:

1. **Feature Engineering**:
   - Criar intera√ß√µes entre vari√°veis (ex: idade √ó educa√ß√£o)
   - Polin√¥mios para vari√°veis num√©ricas
   - Agrega√ß√µes de categorias categ√≥ricas raramente frequentes

2. **Regulariza√ß√£o**:
   - Introduzir L1 (Lasso) ou L2 (Ridge) para evitar overfitting
   - Valida√ß√£o cruzada k-fold para sele√ß√£o de hiperpar√¢metros

3. **Balanceamento de Classes**:
   - Dataset √© desbalanceado (76% classe 0, 24% classe 1)
   - Usar SMOTE, class_weight ou threshold ajustado

4. **Modelos Alternativos**:
   - Random Forest / Gradient Boosting (melhor captura de n√£o-linearidades)
   - Ensemble de m√∫ltiplos modelos

5. **An√°lise de Erros**:
   - Investigar os 39% de falsos negativos (sal√°rios altos preditos como baixos)
   - Pode haver clusters n√£o capturados

---

## üìå Conclus√£o

A **regress√£o log√≠stica √© a abordagem recomendada** para este dataset. Enquanto regress√£o linear fornece interpretabilidade, ela √© inadequada para um problema fundamentalmente classificat√≥rio. A regress√£o log√≠stica combina interpretabilidade (importante), desempenho robusto (AUC=0,91) e alinhamento com o contexto real (decis√µes categ√≥ricas em RH).

---

**Data**: 17 de novembro de 2025  
**Dataset**: Salary Prediction Classification (Kaggle)  
**Ferramentas**: Python, scikit-learn, pandas  
**Tempo de Teste**: 70% treino / 30% teste
